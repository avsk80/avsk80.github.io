# Venkata Sai Krishna Abbaraju | Data Scientist | Data Engineer

[LinkedIn](https://www.linkedin.com/in/vska/) | [GitHub](https://github.com/avsk80) | abbar005@umn.edu | Minneapolis, MN

---

### Technical Skills
- **Core Competencies**: Data Visualization, EDA, Hypothesis Testing, Linear, and Logistic Regression, Supervised, and Unsupervised ML Algorithms, ARIMA, Association Rule Mining, NLP, ANN, CNN, LSTM
- **Programming Languages**: Python, SQL, Scala, Shell Scripting
- **Tools & Frameworks**: PyTorch, Scikit-Learn, Pandas, Numpy, PowerBI, Seaborn, Git, Docker, Jenkins, MLFlow, DVC
- **Big Data Stack**: Hadoop, PySpark (SQL, Structured Streaming, ML), Postgres, Cassandra, Kafka, Hive, HBase, Sqoop, Oozie, Airflow, AWS (S3, EC2, Lambda, EMR, Kinesis, SNS, SQS, Glue, Redshift, CloudWatch), DBT, Delta Lake, Databricks, Data Warehouse Modeling

---

## Education

**University of Minnesota, Twin Cities**  
M.S. Data Science (GPA: 3.85) | *Sep 2022 - Expected Dec 2024*  

**Relevant Coursework:** Big Data Analytics, Statistical Machine Learning, Data Mining, NLP, Deep Learning, Applied Regression Analysis  

**Capstone Project:**  Reviving lost data in manufacturing datasets using Machine Learning (Worked under Professor Jaideep Srivastava and collaborated with [Advisory Aerospace LLC](https://www.factory-twin.com/))
- Worked on improving the data quality of a factory database, by implementing Statistical and ML techniques to impute Job Lead Time, Part Arrival Time, and Standard Time for a part
- Achieved a MAPE of around ~27% using Ensembles-Random Forest and XGBoost

**SRM Institute of Science and Technology**  
B.Tech. in Computer Science and Engineering (GPA: 8.72/10) | *Jun 2015 - May 2019*

---

## Work Experience

**Data Engineer @ Lowe’s**  
*Bangalore, India | Jul 2019 - Aug 2022*

- **TruTax**:
- Implemented a hybrid solution using association rules, K-Means, and BERT to solve incorrect mapping of Lowe’s item to tax code mapping
- Impact: The solution was 90% accurate and saved 20+ hours of manual efforts per week for the finance team 

- **Competitive Intelligence**:
- Developed ETL pipelines and Data Warehouse schema in Hive to ingest daily scarped competitor price data
- Worked with product manager, and business analysts to convert business needs into KPI metrics using SQL and exported the data for Dashboarding
- Impact: improved sales by 85% on 200 high-value items, reducing analysts' workload by 10+ hours weekly
- Achievement: Received **"SPOT"** award in Jan 2021, for delivering results well ahead of the promised timeline

- **Promotion Analytics**:
- Collaborated with cross-functional teams to gather item promotions data from various systems and ingest it into Hive. Built KPIs to assist data scientists in building promo measurement dashboards, and forecasting models
- Achievement: Received **"Team Excellence"** award for Promo Forecast in Jan 2020, for a collective effort to productionize the product  

---

## Featured Projects

### Credit Fraud Detection using ML
[GitHub Repository](https://github.com/avsk80/credit-fraud-detection)

Developed a high-performing LightGBM fraud detection model with 93% ROC-AUC, leveraging PCA, calibrated probabilities, and SHAP analysis for interpretability and reliable fraud predictions on imbalanced data. 

- **Tools/ Techniques**: Python, Sklearn, LightGBM, XGBoost, Chi-Squared, ANOVA, PCA, SHAP
- **Outcome**: Built a reliable and interpretable model to detect fraud cases and take actionable decisions

### Predictive modeling for Obesity classification based on lifestyle and dietary patterns
[GitHub Repository](https://github.com/avsk80/Obesity-classification)

Built a multi-class classification model to predict if a patient is obese or not using demographic, lifestyle, and health data, achieving a weighted F1 of 90% through scaling, and model optimization. 

- **Tools/ Techniques**: Python, Sklearn, Logistic Regression, XGBoost, CatBoost, Random Forest, Chi-Squared, ANOVA, RFE
- **Outcome**: Enabled a means to classify obesity levels, with insights on feature impact that support targeted health interventions and personalized recommendations.

### Value-Based Customer Segmentation  
[GitHub Repository](https://github.com/avsk80/Olist-Customer-segmentation)

Created a segmentation model using RFM metrics and K-Means, achieving a silhouette score of 0.57. Built and managed a Postgres database to support the EDA and downstream modeling tasks.

- **Tools/ Techniques**: Python, SQL, Sklearn, K-Means, RFM analysis, Postgres
- **Outcome**: Enabled targeted customer engagement strategies based on customer value segmentation.

### Real-Time Accident Severity Prediction and Model Monitoring  
[GitHub Repository](https://github.com/avsk80/Real-Time-Accident-Severity)

Developed a streaming pipeline using Kafka as the source and Hive as the sink to predict accident severity. Experimented with various models and achieved an F1 score of 0.77 with Random Forest. Integrated MLflow for experiment tracking and Evidently AI for data drift detection.

- **Tools/ Techniques**: PySpark, Logistic Regression, Gradient Boost, Random Forest, MLflow, Kafka
- **Impact**: Improved model monitoring and retraining approaches in real-time accident prediction pipeline.

### Credit Risk Stratification using ML  
[GitHub Repository](https://github.com/avsk80/credit-risk-assessment)

Created a multi-class credit risk classification model using Statistical ML techniques, 

- **Tools/ Techniques**: Python, Logistic Regression, LDA, XGBoost, Random Forest
- **Outcome**: Provided a means to the businesses to assess if a customer is risky or not based on model-predicted probabilities

### Topic Classification Using Transformers  
[GitHub Repository](https://github.com/avsk80/Topic-Classification-using-Transformers)

Used BERT and Roberta to classify topics in Yahoo Answers, achieving 93% accuracy. Implemented Captum for interpretability, offering insights into model predictions.

- **Tools/ Techniques**: Transformers (BERT, Roberta), transformers_interpret, Pytorch
- **Key Results**: High accuracy with enhanced model interpretability for NLP topic classification tasks.

### NYC Taxi Trip Duration Prediction  
[GitHub Repository](https://github.com/avsk80/nyc-taxi-trip-duration-prediction)

Built an end-to-end model predicting taxi trip durations, incorporating data ingestion, feature engineering, and model deployment with a MAPE of ~12%.

- **Tools/ Techniques**: Python, Random Forest, XGBoost, DVC, MLFlow, Docker, Fast API Deployment
- **Value**: Demonstrated expertise in creating end-to-end ML workflows.

---

## Certifications

- **Apache Spark 3 Certification**
- **Machine Learning Masters**
- **AWS Data Engineering Certification**

---
