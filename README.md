# Venkata Sai Krishna Abbaraju | Data Engineer| Data Scientist | 

[LinkedIn](https://www.linkedin.com/in/vska/) | [GitHub](https://github.com/avsk80) | abbar005@umn.edu | Minneapolis, MN

---

### Technical Skills
- **Programming Languages**: Python, SQL, Scala, Shell Scripting
- **Tools & Frameworks**: PyTorch, Scikit-Learn, Pandas, Numpy, Tableau, Seaborn, Git, Docker, Jenkins, MLFlow, DVC
- **Big Data Stack**: Hadoop, Pyspark (SQL, Structured Streaming, ML), Postgres, Cassandra, Kafka, Hive, Airflow, DBT, Delta Lake
- **Azure Cloud**: Datalake, Data Factory, Databricks, Synapse Analytics, SQL DB, Eventhub, DevOps
- **ML and Analytics**: Data Visualization, EDA, Hypothesis Testing, Linear, and Logistic Regression, Supervised, and Unsupervised ML Algorithms, ARIMA, Association Rule Mining, NLP, ANN, CNN, LSTM
- **AWS Cloud**: S3, EC2, Lambda, EMR, Kinesis, SNS, SQS, Glue, Redshift, CloudWatch

---

## Education

**University of Minnesota, Twin Cities**  
M.S. Data Science (GPA: 3.85) | *Sep 2022 - Feb 2025*  

**Relevant Coursework:** Big Data Analytics, Statistical Machine Learning, Data Mining, NLP, Deep Learning, Applied Regression Analysis  

**Capstone Project:**  Reviving lost data in manufacturing datasets using Machine Learning (Worked under Professor Jaideep Srivastava)
- Collaborated with [Advisory Aerospace LLC](https://www.factory-twin.com/) to improve data quality in factory ERP datasets
- Achieved a MAPE of around ~27% using Ensembles-Random Forest and XGBoost

**SRM Institute of Science and Technology**  
B.Tech. in Computer Science and Engineering (GPA: 8.72/10) | *Jun 2015 - May 2019*

---

## Work Experience

**Data Engineer @ Lowe’s**  
*Bangalore, India | Jul 2019 - Aug 2022*

- **TruTax**:
- Implemented a hybrid solution using association rules, K-Means, and BERT to solve incorrect mapping of Lowe’s item to tax code mapping
- Impact: The solution was 90% accurate and saved 20+ hours of manual efforts per week for the finance team 

- **Competitive Intelligence**:
- Developed ETL pipelines and Data Warehouse schema in Hive and BigQuery to ingest daily scarped competitor price data
- Worked with product manager, and business analysts to convert business needs into KPI metrics using Presto and exported the data for Dashboarding
- Impact: improved sales by 85% on 200 high-value items, reducing analysts' workload by 10+ hours weekly
- Achievement: Received **"SPOT"** award in Jan 2021, for delivering results well ahead of the promised timeline

- **Promotion Analytics**:
- Collaborated with cross-functional teams to gather item promotions data from various systems and ingest it into Hive. Built KPIs to assist data scientists in building promo measurement dashboards, and forecasting models
- Achievement: Received **"Team Excellence"** award for Promo Forecast in Jan 2020, for a collective effort to productionize the product  

---

## Featured Projects

### Credit Fraud Detection using ML
[GitHub Repository](https://github.com/avsk80/credit-fraud-detection)

Developed a high-performing LightGBM fraud detection model with 93% ROC-AUC, leveraging PCA, calibrated probabilities, and SHAP analysis for interpretability and reliable fraud predictions on imbalanced data. 

- **Tools/ Techniques**: Python, Sklearn, LightGBM, XGBoost, Chi-Squared, ANOVA, PCA, SHAP
- **Outcome**: Built a reliable and interpretable model to detect fraud cases and take actionable decisions

### Healthcare Revenue Cycle Management Analytics in Azure Cloud
[GitHub Repository](https://github.com/avsk80/rcm_data_engineering)

Developed an end-to-end RCM big data pipeline in Azure Cloud that gathers data from multiple data sources like SQL DB, CSV, APIs and built a Data Warehouse schema to support downstream analytics and business metrics 

- **Tools/ Techniques**: Python, Azure Services - Azure SQL DB, Synapse, Data lake, Databricks, Data Factory, Key Vault
- **Outcome**: Built an efficient, generic, metadata-driven, and scalable big data pipeline that streamlines the data flow for analytics purposes 

### Predictive modeling for Obesity classification based on lifestyle and dietary patterns
[GitHub Repository](https://github.com/avsk80/Obesity-classification)

Built a multi-class classification model to predict if a patient is obese or not using demographic, lifestyle, and health data, achieving a weighted F1 of 90% through scaling, and model optimization. 

- **Tools/ Techniques**: Python, Sklearn, Logistic Regression, XGBoost, CatBoost, Random Forest, Chi-Squared, ANOVA, RFE
- **Outcome**: Enabled a means to classify obesity levels, with insights on feature impact that support targeted health interventions and personalized recommendations.

### Value-Based Customer Segmentation  
[GitHub Repository](https://github.com/avsk80/Olist-Customer-segmentation)

Created a segmentation model using RFM metrics and K-Means, achieving a silhouette score of 0.57. Built and managed a Postgres database to support the EDA and downstream modeling tasks.

- **Tools/ Techniques**: Python, SQL, Sklearn, K-Means, RFM analysis, Postgres
- **Outcome**: Enabled targeted customer engagement strategies based on customer value segmentation.

### Real-Time Accident Severity Prediction and Model Monitoring  
[GitHub Repository](https://github.com/avsk80/Real-Time-Accident-Severity)

Developed a streaming pipeline using Kafka as the source and Hive as the sink to predict accident severity. Experimented with various models and achieved an F1 score of 0.77 with Random Forest. Integrated MLflow for experiment tracking and Evidently AI for data drift detection.

- **Tools/ Techniques**: PySpark, Logistic Regression, Gradient Boost, Random Forest, MLflow, Kafka
- **Impact**: Improved model monitoring and retraining approaches in real-time accident prediction pipeline.

### Credit Risk Stratification using ML  
[GitHub Repository](https://github.com/avsk80/credit-risk-assessment)

Created a multi-class credit risk classification model using Statistical ML techniques, and leveraged a variety of feature engineering techniques yielding a weighted F1 of 0.85.

- **Tools/ Techniques**: Python, Logistic Regression, LDA, XGBoost, Random Forest, Chi-Squared, 
- **Outcome**: Provided a means to the businesses to assess if a customer is risky or not based on model-predicted probabilities and reduced false negatives

### Topic Classification Using Transformers  
[GitHub Repository](https://github.com/avsk80/Topic-Classification-using-Transformers)

Used BERT and Roberta to classify topics in Yahoo Answers, achieving 93% accuracy. Implemented Captum for interpretability, offering insights into model predictions.

- **Tools/ Techniques**: Transformers (BERT, Roberta), transformers_interpret, Pytorch
- **Key Results**: High accuracy with enhanced model interpretability for NLP topic classification tasks.

### NYC Taxi Trip Duration Prediction  
[GitHub Repository](https://github.com/avsk80/nyc-taxi-trip-duration-prediction)

Built an end-to-end model predicting taxi trip durations, incorporating data ingestion, feature engineering, and model deployment with a MAPE of ~12%.

- **Tools/ Techniques**: Python, Random Forest, XGBoost, DVC, MLFlow, Docker, Fast API Deployment
- **Value**: Demonstrated expertise in creating end-to-end ML workflows.

---

## Certifications

- **[Apache Spark 3 Certification](https://github.com/avsk80/avsk80.github.io/blob/main/pyspark-cert.pdf)**
- **[Azure Databricks Certification](https://github.com/avsk80/avsk80.github.io/blob/main/azure-DB-cert.pdf)**
- **[Microsoft Azure Data Engineer](https://github.com/avsk80/avsk80.github.io/blob/main/AZ-DE-CERTIFICATE.pdf)**

---
