# Venkata Sai Krishna Abbaraju | Data Scientist

[LinkedIn](https://www.linkedin.com/in/vska/) | [GitHub](https://github.com/avsk80) | abbar005@umn.edu | Minneapolis, MN

---

### Technical Skills
- **Core Competencies**: Linear Regression, Logistic Regression, Random Forest, Data Visualization, EDA, Clustering, ARIMA, LLMs, Association Rule Mining, NLP, ANN, CNN, LSTM
- **Programming Languages**: Python, SQL, Scala, Shell Scripting
- **Tools & Frameworks**: PyTorch, Scikit-Learn, Pandas, Numpy, PowerBI, Seaborn, Git, Docker, Jenkins, MLFlow, DVC
- **Big Data Stack**: Hadoop, PySpark (SQL, Structured Streaming, ML), Postgres, Cassandra, Kafka, Hive, HBase, Sqoop, Oozie, Airflow, AWS (S3, EC2, Lambda, EMR, Kinesis, SNS, SQS, Glue, Redshift, CloudWatch), DBT, Delta Lake, Data Warehouse Modeling

---

## Education

**University of Minnesota, Twin Cities**  
M.S. Data Science (GPA: 3.85) | *Sep 2022 - Expected Dec 2024*  
Relevant Coursework: Big Data Analytics, Data Mining, NLP, Deep Learning, Applied Regression Analysis  
Capstone Project: Data quality improvement for manufacturing datasets using ML (collaborated with Advisory Aerospace LLC)

**SRM Institute of Science and Technology**  
B.Tech. in Computer Science and Engineering (GPA: 8.72/10) | *Jun 2015 - May 2019*

---

## Work Experience

**Data Engineer @ Loweâ€™s**  
*Bangalore, India | Jul 2019 - Aug 2022*

- **TruTax Project**: Built a hybrid solution using association rules, K-Means, and BERT, achieving 90% accuracy in mapping items to tax codes, saving 30+ hours per month for the finance team.
- **Competitive Intelligence**: Developed ETL pipelines and metrics to improve sales by 85% across key stores, reducing analysts' workload by 10+ hours weekly.  
- **Promotion Analytics**: Collaborated to create KPIs for promo measurement dashboards; migrated 20 TB data and optimized query processing using Apache Druid, resulting in a 20% speed improvement.

---

## Featured Projects

### Real-Time Accident Severity Prediction and Model Monitoring  
[GitHub Repository](https://github.com/avsk80/Real-Time-Accident-Severity)

Developed a streaming pipeline via Kafka to predict accident severity, storing results in Hive. Experimented with various models and achieved an F1 score of 0.77, implementing MLflow for experiment tracking and Evidently AI for data drift detection.

- **Tools**: PySpark, Logistic Regression, Gradient Boost, Random Forest, MLflow, Kafka
- **Impact**: Improved real-time response capabilities in accident prediction pipelines.

### Value-Based Customer Segmentation  
[GitHub Repository](https://github.com/avsk80/Olist-Customer-segmentation)

Created a segmentation model using RFM metrics and K-Means, achieving a silhouette score of 0.57. Built and managed a Postgres database to support the analysis.

- **Tools**: Python, SQL, K-Means, Postgres
- **Outcome**: Enabled targeted customer engagement strategies based on customer value segmentation.

### Topic Classification Using Transformers  
[GitHub Repository](https://github.com/avsk80/Topic-Classification-using-Transformers)

Used BERT and Roberta to classify topics in Yahoo Answers, achieving 93% accuracy. Implemented SHAP for interpretability, offering insights into model predictions.

- **Tools**: Transformers (BERT, Roberta), SHAP, Python
- **Key Results**: High accuracy with enhanced model interpretability for NLP classification tasks.

### NYC Taxi Trip Duration Prediction  
[GitHub Repository](https://github.com/avsk80/nyc-taxi-trip-duration-prediction)

Built an end-to-end model predicting taxi trip durations, incorporating data ingestion, feature engineering, and model deployment with a MAPE of ~12%.

- **Tools**: Python, Random Forest, Feature Engineering, API Deployment
- **Value**: Demonstrated expertise in creating scalable ML workflows.

---

## Certifications

- **Apache Spark 3 Certification**
- **Machine Learning Masters**
- **AWS Data Engineering Certification**

---
